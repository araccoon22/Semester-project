---
title: "MMNL Preference Space"
output:
  html_document: default
  pdf_document: default
date: "2024-03-11"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Data description
Mixed logit model on Swiss route choice data, uncorrelated Lognormals in preference space

###LOAD LIBRARY AND DEFINE CORE SETTINGS                     

```{r}
### Clear memory
rm(list = ls())

### Load Apollo library
library(apollo)

#load dplyr library
library(dplyr)

### Initialise code
apollo_initialise()

### Set core controls
apollo_control = list(
  modelName       = "MMNL_preference_space",
  modelDescr      = "Mixed logit model on Swiss route choice data, uncorrelated Lognormals in preference space",
  indivID         = "ID",  
  nCores          = 4,
  outputDirectory = "output"
)

```
### CPU and RAM Monitoring:

```{r}
monitor_system <- function(duration_minute) {
  duration <- duration_minute * 60  # transforming the argument so it's in minutes instead of seconds
  data <- data.frame(`Time` = numeric(), `CPU Usage (%)` = numeric(), `RAM Usage (%)` = numeric())
  start_time <- Sys.time()
  
  while (difftime(Sys.time(), start_time, units = "secs") < duration) {
    elapsed_time <- difftime(Sys.time(), start_time, units = "secs")
    cpu_percent <- system("wmic cpu get loadpercentage | findstr [0-9]", intern = TRUE)
    ram_info <- system("wmic OS get FreePhysicalMemory /Value", intern = TRUE)
    ram_percent <- 100 - as.numeric(sub("\\D", "", ram_info)) / as.numeric(system("wmic computersystem get TotalPhysicalMemory /Value", intern = TRUE)) * 100
    
    data <- rbind(data, data.frame(`Time` = elapsed_time, `CPU Usage (%)` = as.numeric(cpu_percent), `RAM Usage (%)` = ram_percent))
    
    Sys.sleep(60)  # measure the CPU + RAM every minute
  }
  
  return(data)
}

# Example usage:
# df_monitor <- monitor_system(5) # Monitor for 5 minutes

```


### LOAD DATA AND APPLY ANY TRANSFORMATIONS                  

```{r}
### Loading data from package
### if data is to be loaded from a file (e.g. called data.csv), 
### the code would be: database = read.csv("data.csv",header=TRUE)
database = apollo_swissRouteChoiceData
### for data dictionary, use ?apollo_swissRouteChoiceData

```

### ANALYSIS OF CHOICES

```{r}
### Note this is unlabelled data, so we are doing this for an illustration of cheap vs expensive
### Define settings for analysis of choice data to be conducted prior to model estimation

choiceAnalysis_settings <- list(
  alternatives = c(cheap=1, expensive=2),
  choiceVar    = (1*((database$choice==1)*(database$tc1<=database$tc2)+(database$choice==2)*(database$tc1>=database$tc2))
                  +2*((database$choice==1)*(database$tc1>=database$tc2)+(database$choice==2)*(database$tc1<=database$tc2))),
  explanators  = database[,c("car_availability","hh_inc_abs","business")]
)

### Run function to analyse choice data
apollo_choiceAnalysis(choiceAnalysis_settings, apollo_control, database)

```

### DEFINE MODEL PARAMETERS

```{r}
### Vector of parameters, including any that are kept fixed in estimation
apollo_beta = c(asc            = 0,
                mu_log_b_tt    = -3,
                sigma_log_b_tt = -0.01,
                mu_log_b_tc    = -3,
                sigma_log_b_tc = -0.01,
                mu_log_b_hw    = -3,
                sigma_log_b_hw = -0.01,
                mu_log_b_ch    = -3,
                sigma_log_b_ch = -0.01)

### Vector with names (in quotes) of parameters to be kept fixed at their starting value in apollo_beta, use apollo_beta_fixed = c() if none
apollo_fixed = c("asc")

```


### DEFINE RANDOM COMPONENTS 

```{r}
### Set parameters for generating draws
apollo_draws = list(
  interDrawsType = "halton",
  interNDraws    = 500,
  interUnifDraws = c(),
  interNormDraws = c("draws_tt","draws_tc","draws_hw","draws_ch"),  #Standard Normal dist draws
  intraDrawsType = "halton",
  intraNDraws    = 0,
  intraUnifDraws = c(),
  intraNormDraws = c()
)

### Create random parameters
apollo_randCoeff = function(apollo_beta, apollo_inputs){
  randcoeff = list()

  randcoeff[["b_tt"]] = -exp( mu_log_b_tt + sigma_log_b_tt * draws_tt )
  randcoeff[["b_tc"]] = -exp( mu_log_b_tc + sigma_log_b_tc * draws_tc )
  randcoeff[["b_hw"]] = -exp( mu_log_b_hw + sigma_log_b_hw * draws_hw )
  randcoeff[["b_ch"]] = -exp( mu_log_b_ch + sigma_log_b_ch * draws_ch )

  return(randcoeff)
}


```

### GROUP AND VALIDATE INPUTS

```{r}
apollo_inputs = apollo_validateInputs()

```

### DEFINE MODEL AND LIKELIHOOD FUNCTION

```{r}
apollo_probabilities=function(apollo_beta, apollo_inputs, functionality="estimate"){

  ### Function initialisation: do not change the following three commands
  ### Attach inputs and detach after function exit
  apollo_attach(apollo_beta, apollo_inputs)
  on.exit(apollo_detach(apollo_beta, apollo_inputs))

  ### Create list of probabilities P
  P = list()

  ### List of utilities: these must use the same names as in mnl_settings, order is irrelevant
  V = list()
  V[["alt1"]] = asc + b_tt * tt1 + b_tc * tc1 + b_hw * hw1 + b_ch * ch1
  V[["alt2"]] = b_tt * tt2 + b_tc * tc2 + b_hw * hw2 + b_ch * ch2

  ### Define settings for MNL model component
  mnl_settings = list(
    alternatives  = c(alt1=1, alt2=2),
    avail         = list(alt1=1, alt2=1),
    choiceVar     = choice,
    utilities     = V
  )

  ### Compute probabilities using MNL model
  P[["model"]] = apollo_mnl(mnl_settings, functionality)

  ### Take product across observation for same individual
  P = apollo_panelProd(P, apollo_inputs, functionality)

  ### Average across inter-individual draws
  P = apollo_avgInterDraws(P, apollo_inputs, functionality)

  ### Prepare and return outputs of function
  P = apollo_prepareProb(P, apollo_inputs, functionality)
  return(P)
}

```

### MODEL ESTIMATION

```{r}

model = apollo_estimate(apollo_beta, apollo_fixed,apollo_probabilities, apollo_inputs)
```

### MODEL OUTPUTS

```{r}


apollo_modelOutput(model) #(FORMATTED OUTPUT (TO SCREEN))

apollo_saveOutput(model) #(FORMATTED OUTPUT (TO FILE, using model name))
```

